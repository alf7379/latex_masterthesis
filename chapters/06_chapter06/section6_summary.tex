% !TeX root = ../../main.tex
% Add the above to each chapter to make compiling the PDF easier in some editors.

\section{Summary}

In this thesis four interactive segmentation methods were evaluated with the use of a benchmark study performed by real users.
Thereby, the segmentation methods are rated based on their performance and generalization capabilities over various image domains and users.
%%% Review of contests covered in the thesis.

% TODO Hier bitte keine Wiederholung der Kapitelaufzählung!            Bitte auch Kapitel ohne Erkenntnisse weglassen und stattdessen den Fokus auf die Ergebnisse und die Schlüsse daraus richten.            Was hast du gezeigt was wurde gemacht und was wurde festgestellt.
% Kreis schließen zur Einleitung

% Description of the single chapters (middle detail with focus on the outcome -> repeat the dicovered results)
%%% Chapter 1
%%% Chapter 2 
\gls{ml} is introduced quickly, while the task of semantic segmentation is examined in detail.
Further, interactive segmentation and different approaches are introduced.
Of particular focus are the methods based on \gls{dl}, \gls{dextr} and \gls{iog}.
Methods for statistical analysis are introduced that are used for the evaluation.

%%% Chapter 3
As manual baseline polygon drawing is introduced, while as classical interactive segmentation method the watershed transformation is presented.
Furthermore, the \gls{dextr} \cite{Man18-DEXTR} and \gls{iog} \cite{Zha20-IOG} method are presented as representatives of state-of-the-art interactive segmentation methods based on \gls{dl}.

%%% Chapter 4
The compilation of the image dataset for the benchmark study is described by the presentation of the considered image attributes and the image domains $ standard $, $ urban $, $ industrail $, and $ anomaly $.
Further, it is described what user statistics are recorded in the benchmark study and what the process of participating in the benchmark study was like.
% TODO Mehr beschreiben was geschaffen wurde (unabhängig vom Kapitel) Was zeichnet den neuen Benchmark aus? -> echte user und eigenes Dataset

%%% Chapter 5
% TODO Die Art der Formulierungen ist untypisch für eine Conclusion: Man beschreibt mehr was man herausgefunden hat und weniger was man vorhat und wie man genau methodisch vorgegangen ist..s
% DL-based methods vs. classical methods
The results of the benchmark study and further experiments are evaluated in Chapter \ref{ord:ch5}.
% Hier wird es langsam interessant.
To begin the research question posed in Chapter \ref{ord:ch1} is examined, if interactive segmentation methods based on \gls{dl} improve the labeling process compared to methods without \gls{dl}.
The comparison is based on the benchmark results and takes the accuracy and the annotation time into account as presented in Section \ref{ord:ch5:sec1}.
The \gls{dextr} method is slightly superior based on the $ IoU $, while the the \gls{iog} method performs worst.
Therefore, in this regard neither classical or \gls{dl} based methods are advantageous, but as the methods polygon and \gls{dextr} achieve top accuracy.
With respect to annotation time, it could be clearly established that the \gls{dl} based methods (\gls{dextr} and \gls{iog}) are significantly faster in application than the classical methods (polygon and watershed).
The \gls{dextr} method stands out due to good performance on both with respect to $ IoU $ and $ time $.

% Generalization over domains
The $ IoU $ is similar over the image domains, except for the domain $ anomaly $, what is caused by the basic nature of anomaly images.
In terms of the annotation time, it is discovered that the domains $ standard $ and $ urban $ are more elaborate to annotate, which is evident across all methods.

% Generalization over users
The annotation time for the \gls{dextr} and \gls{iog} method contains less variance over the users.
In relation to accuracy the \gls{dextr} method performs the most constant over various users.
It is experienced, that the annotation time highly depends on the individual user.
In general, the \gls{dextr} method generalizes best over various image domains and user based on the results from the user benchmark.

The conclusion that can be drawn from the survey is that a pleasant user experience requires a good performing method and vice versa.
 % TODO ab hier keine Anmerkungen mehr -> Conclusion umschreiben
Last, in Section \ref{ord:ch5:sec5_retrain} the statement from Manisis \etal is examined, that \gls{dl} models trained on \gls{dextr} annotations perform equally as models trained with the original \gls{gt} \cite{Man18-DEXTR}.
The experiments of this thesis show, that this statement can be confirmed in a limited way.
The different models perform similar based on the \gls{map}, but the models trained on the \gls{dextr} annotations perform significantly worse for high \gls{iou} values. 

% Void Pixel 
An additional insight is delivered about the use of \gls{vp} in the PASCAL \gls{voc} dataset \cite{Eve20-PascalVOC}.
As presented in Table \ref{tab:ch5:tests_on_datasets} the \gls{miou} differs significantly with and without the use of \gls{vp}.
By presenting the results with \gls{vp}, unrealistically high expectations are created that cannot be met on real world data or datasets without \gls{vp}.
The inclusion of the results with \gls{vp} would lead to more transparently and awareness of the purpose of \gls{vp}.

% Final tought
% Antwort auf Research Frage -> if interactive segmentation methods based on \gls{dl} improve the process of labeling based on the annotation time and accuracy.
In conclusion, it can be said that interactive segmentation methods based on \gls{dl} perform better than methods without \gls{dl} based on the annotation time, while in terms of accuracy, both methods are competitive on a similar level.
The generalization capabilities over different image domains are similar.
The \gls{dl} based methods generalize better over various users, which is most probably due to the guided design of the user interaction.
Thereby, the \gls{dextr} method with the direct and simple user interactions performs best on the benchmark study.


%%% Future Work
 
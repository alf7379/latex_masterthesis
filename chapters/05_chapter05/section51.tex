% !TeX root = ../../main.tex
% Add the above to each chapter to make compiling the PDF easier in some editors.

\section{Improvement In Time And IoU}\label{ord:ch5:sec1}

This section focuses on the annotation time $time_{annot}$ and the precision measure $IoU$ from the benchmark measurements.
First, the relationship between time and user clicks is examined.
Second, the accuracy in terms of $ IoU $ to the GT annotations is evaluated for the four benchmark methods.
Third, the same evaluation evaluation is performed for $time_{annot}$. 
In Figure \ref{fig:ch5:sec1:iou_vs_time} an initial insight on the benchmark data is provided, by a plot of $ IoU $ against $ time $.
The plot shows, that most annotations have high $ IoU $ and required less than 50 seconds in creation.
It is noticeable, that the outliers with a low $ IoU $ are from all methods, while annotations with a long annotation time  are mostly from the methods polygon and watershed.
In extreme cases the $ IoU $ is surprisingly small or the $ time $ is very long.
One reason why the $ IoU $ is generally very high is that the participating users are only satisfied with annotations of this quality.

\begin{figure}
	\centering
	\includegraphics[width=0.8\textwidth]{figures/chap51_iou_vs_time.png}
	\caption[Scatter plot of $ IoU $ and $ time $]{
		Scatter plot of $ IoU $ against $ time $.
		The majority of the points have a high $ IoU $ and low $ time $, but there are many outliers.
		Annotations with a low $ IoU $ are produced by all methods equally, while for a high $ time $ mostly the polygon and watershed method are used.	
	} \label{fig:ch5:sec1:iou_vs_time}
\end{figure}

\subsection{Correlation Between Time And Clicks}\label{ord:ch5:sec1:subsec1}

% RE-1464 
In the following the relationship between time and the user interaction as clicks and strokes is investigated, in order to promote the further analysis, which is strongly based on $time_{annot}$. 
As introduced in Subsection \ref{ch2:sec3:eval_interactive_methods}, a common metric to measure the level of user interaction is the number of clicks $n_{clicks}$.
Thereby, $n_{clicks}$ functions as indicator for $time_{annot}$, which is the more meaningful variable in terms of ranking the amount of user interaction.
In general, $n_{clicks}$ is not necessarily a fair indicator, because the time per click may differ for user interaction in methods with varying complexity.
For example, clicking approximately on the center of the object is in general much quicker than clicking on the right-most point of the object which has first to be identified.

In the benchmark study the user interaction was recorded by the number of clicks $n_{clicks}$, number of strokes $n_{strokes}$, and required time to perform the strokes $time_{strokes}$.
The informative value of each single variable is limited, because the user interaction may consists out of either only clicks or strokes, or a combination of both.
The stroke related variables are combined to the weighted strokes $ ws $ by
\begin{equation} \label{equ:ws}
	ws = f_{stroke} \cdot time_{strokes} + n_{strokes} 
\end{equation}
with the weighting factor $ f_{stroke} $.
Based on a manual analysis of the data $ f_{stroke} = 1.0 $ was determined, so that one second of stroking has the same value as one click, which is expected to be a fair trade-off between clicks and strokes.
To facilitate the comparison a single variable $ cws $ is established by 
\begin{equation}
	cws = n_{clicks} + ws
\end{equation}
which combines clicks and strokes.

The relationship of the single variables is presented within a correlation matrix in Table \ref{tab:ch5:correlation-matrix}.
This includes the annotations from all four benchmark methods, between which no distinction is made in this subsection.
% Correlation between time_{annot} and cws
The correlation between the time and weighted clicks and strokes $ corr \left(time_{annot}, cws \right) = 0.8610 $ is strong.
This confirms the relationship between these variables and supports their suitability for further evaluation.

Although, it should be noted that, the correlation value of $ time_{annot} $ and $ cws $ is not maximal.
This assists the hypothesis that $ cws $ does not constitute a flawless representation of $ time_{annot} $ and thereby is not a perfectly suitable performance measure.
However, $ cws $ is still sufficient for the comparison of interactive methods, but the limitations have to be noted.
For the further evaluation mostly $ time_{annot} $ will be used to represent the user interaction.

Attention should be drawn also to the correlation between \gls{iou} and time \linebreak $ corr \left(time_{annot}, IoU \right) = 0.0379 $.
So in general, a long annotation time does not necessarily correspond to a high \gls{iou}.
This indicates, that some methods can achieve a good IoU in little time, while other methods require more time.
The annotation time is evaluated in detail in Subsection \ref{ord:ch5:sec1:subsec3}. 

\begin{table}[h!]
	\centering
	\resizebox{\textwidth}{!}{
	\begin{tabular}{l|c c c c c c c}
		\toprule 		
							& $ time_{annot} $ 	
										& $ n_{clicks} $ 	
													& $ n_{strokes} $ 
																& $ time_{strokes} $ 
																			& $ ws $ 	& $ cws $   & $ IoU $ \\
		\midrule
		$ time_{annot} $	& 1 		& - 		&  -		& - 		& - 		& - 		& - \\ 
		$ n_{clicks} $		& 0.7085	& 1 		&  - 		& - 		& - 		& - 		& - \\ 
		$ n_{strokes} $ 	& 0.7391 	& 0.6169 	&  1 		& -		   	& - 		& - 		& - \\ 	
		$ time_{strokes} $ 	& 0.7069 	& 0.3309	&  0.7949	&  1 		& - 		& - 		& - \\ 
		$ ws $				& 0.7500 	& 0.4376 	&  0.8973	&  0.9811 	&  1 		& - 		& - \\ 
		$ cws $		  		& 0.8610 	& 0.8261	&  0.9028	&  0.7976 	&  0.8682 	& 1 		& - \\ 
		$ IoU $    			& 0.0379 	& 0.0455	&  0.0004	& -0.0101 	& -0.0073 	& 0.0206 	& 1 \\ 								
		\bottomrule
	\end{tabular}}
	\caption[Correlation table]{
		Correlation table based on the \textit{Pearson} standard correlation coefficient \cite{Kirch08-CorrPearson}.
		The redundant part of the table is left empty. 
		The variables $ n_{clicks} $, $ n_{strokes} $, $ time_{strokes} $, and $ ws $ all show a intermediate correlation with $ time_{annot} $, while their combination $ cws $ shows a strong correlation of $ 0.8610 $. 
		The correlation between $ IoU $ and $ time_{annot} $ indicates almost no relationship.
	}\label{tab:ch5:correlation-matrix}
\end{table}


\subsection{Analysis Of IoU}\label{ord:ch5:sec1:subsec2}

In the following the $IoU$ is evaluated in detail by the application of the statistical methods introduced in Section \ref{ord:ch2:sec4}.

% Limitation - The resulting mask was shown to the user, which may lead to futher editing resulting in a better IoU and more time
\paragraph{Limitation of the analysis}
It may be problematic that the design of the user interaction differs between the benchmark methods.
For the \gls{dextr} and \gls{iog} method the user interaction is strictly guided due to the limited amount of clicks for the initial prediction.
For the polygon and watershed method the user interaction is designed more open and, therefore, gives the user more freedom of choice.
With the open design of these methods, the user may feel that he has not applied them well enough, if the shown results are unsatisfactory.
As a results, the user may directly further edit the initial annotation in order to improve it.
In contrast the strong guidance for the \gls{dextr} and \gls{iog} method gives the user confidence in having used the method correctly and assigns an insufficient annotation to the method itself.
In general, users may find it more difficult to accept bad annotations, if the method gave them a lot of freedom in creating it. 
This assumption also applies in reverse, for easy acceptance by methods with strong guidance.
Therefore, the annotations may have a similar \gls{iou}, but the time spent differs as shown in Subsection \ref{ord:ch2:sec1:subsec3}.
If the annotations had to be created in a certain time, the \gls{iou} would also be different, but it was decided against such a setup, for convenience.


\subsubsection{Data Transformation}
Subsection \ref{ord:ch2:sec4:subsec1} already introduced the normality assumption for statistical methods such as the Student's t-test and suggests a transformation of the data.
The histogram of the $IoU$ illustrates that it is not distributed normally as shown in Figure \ref{fig:ch5:sec1:data_raw}.
The data points are heavily skewed to the right. 
This is caused by many data points with a high \gls{iou} and comparatively few with a low \gls{iou}, produced by general good segmentation results.

In order to normalize the raw sample $ X_{raw} $, \cite{PS16-Statistics} suggests the logarithmic function
\begin{equation} \label{equ:trans_iou}
	X_{trans} = \frac{1}{2} \cdot \log \left( \frac{1 + X_{raw}}{1 - X_{raw}}\right) 
\end{equation}
to transform $ X_{raw} $ into $ X_{trans} $.
In Figure \ref{fig:ch5:sec1:data_transformed}, $ X_{trans} $ demonstrates the characteristics of a normal distribution.
Further the normality of $ X_{trans} $ is demonstrated by the probability plot shown in Figure \ref{fig:ch5:sec1:probplot}.

\begin{figure} [h]
	\centering
	\begin{subfigure}[t]{0.3\textwidth}
		\centering
		\includegraphics[width=\textwidth]{figures/chap51_iou_raw.png}
		\caption{
			Histogram of the $ IoU $ values as raw and unprocessed sample $ X_{raw} $.
		}\label{fig:ch5:sec1:data_raw}
	\end{subfigure}
	\hfill
	\begin{subfigure}[t]{0.3\textwidth}
		\centering
		\includegraphics[width=\textwidth]{figures/chap51_iou_trans.png}
		\caption{
			Histogram of the transformed sample $ X_{trans} $ with a fitted normal distribution.
		} \label{fig:ch5:sec1:data_transformed}
	\end{subfigure}
	\hfill
	\begin{subfigure}[t]{0.3\textwidth}
		\centering
		\includegraphics[width=\textwidth]{figures/chap51_iou_probplot.png}
		\caption{
			Normal probability plot of $ X_{trans} $.
		}\label{fig:ch5:sec1:probplot}
	\end{subfigure}
	\caption[Sample Transformation $ IoU $]{		
		The sample $ X $ is transformed to achieve a normal distribution.
		As shown in a) $ X_{raw} $ is skewed to the right and not distributed normally.
		The transformation was performed by Equation \ref{equ:trans_iou}.
		The result of the transformation $ X_{trans} $ is normally distributed, as illustrated in b) by the curve of the fitted normal distribution.
		In c) a normal probability plot confirms the normality in $ X_{trans} $.
	}\label{fig:ch5:sec1:data_transformation_iou}
\end{figure}


% Hypothesis testing
\subsubsection{Hypothesis Testing}

In the following multiple hypothesis tests are described, which divide the sample in two and four factors.

First, it is tested if \gls{dl} based methods (\gls{iog} and \gls{dextr}) are advantageous over classical methods (polygon and watershed).
This more general test results in the two factors $ IoU_{classical} $ and $ IoU_{dl} $.
Three different hypothesis tests are applied on these two factors.
Student's t-test evaluates the mean of the factors, Kruskal-Wallis the median of the factors, and Mann-Whitney the general tendency of the factors as introduced in Subsection \ref{ord:ch2:sec4}.
The detailed settings and results of the tests are presented in Table \ref{tab:ch5:tests_on_iou}.
All three tests come to the conclusion to accept $ H_{0} $, that in general the $ IoU $ of \gls{dl} based methods do not differ significantly from the $ IoU $ of classical methods.
The information value of this conclusion is especially strong, due to the application of three different tests with various null hypotheses.

\begin{table}[h!]
	\centering
	\resizebox{\textwidth}{!}{
	\begin{tabular}{l|c c c}
		\toprule 		
			 			& Student's t-test	& Kruskal-Wallis test 	& Mann-Whitney U-test \\
		\midrule
		data			& $ X_{trans} $		& $ X_{raw} $ 	 		& $ X_{raw} $ 	\\ 
		$H_{0}$			& $ \overline{IoU}_{classical} = \overline{IoU}_{dl} $ 
											& $ med \left( IoU_{classical} \right)  = med \left( IoU_{dl} \right) $ 
																	& $ ten \left( IoU_{dl} \right)  = ten \left( IoU_{classical} \right) $ 	\\
		$ H_{A} $		& $ \overline{IoU}_{classical} < \overline{IoU}_{dl} $ 
											& $ med \left( IoU_{classical} \right) < med \left( IoU_{dl} \right) $ 
																	& $ ten \left( IoU_{dl} \right) \not= ten \left( IoU_{classical} \right) $ 	\\
		$ \alpha $		& $ 5\% $ 			& $ 5\% $ 		 		& $ 5\% $ 		\\ 	
		Statistic		& 0.3494			& 825786	     		& 0.0035    	\\ 
		$ \textnormal{\textit{p-value}} $ 
						& 0.7268 			& 0.4765 		 		& 0.9529		\\ 
		$ H_{0} $		& accepted 			& accepted		 		& accepted 		\\
		\bottomrule
	\end{tabular}}
	\caption[Hypothesis Tests on $ IoU $]{
		Overview and results of the statistical tests.
		The $ IoU $ is evaluated by various values as the mean, median and tendency of the sample.
		Both factors $ IoU_{classical} $ and $ IoU_{dl} $ contain 1286 annotations.
		If the $ \textnormal{\textit{p-value}} $ is greater than the significance level $ \alpha $, $ H_{0} $ is accepted.
		The same result is achieved by all three different statistical tests, which supports its reliability.
	}\label{tab:ch5:tests_on_iou}	
\end{table}

% Kruskal-Wallis Test for four factors rejects H0.
Second, the $ IoU $ is evaluated in detail, thereby the Kruskal-Wallis test is applied using the four benchmark methods as factors.
The corresponding null hypothesis 
\begin{equation}
	H_{0}: med \left( IoU_{Polygon} \right) = med \left( IoU_{Watershed} \right) = med \left( IoU_{IOG} \right) = med \left( IoU_{DEXTR} \right)
\end{equation}
states, that the median values do not differ significantly.
$ H_{A} $ assumes that $ H_{0} $ is not true, but does not define which factor is different.
As result the statistic returns $ \textnormal{\textit{p-value}} = 7.8 \cdot 10 ^{-8} $, therefore, $ H_{0} $ is rejected and $ H_{A} $ accepted at $ \alpha=5\% $.

It can be determined what factors differ significantly, by the application of the DSCFs  test \cite{CF91-dscf}.
In this test it is shown that, $ med \left( IoU_{DEXTR} \right) $ is greater, while $ med \left( IoU_{IOG} \right) $ is lower than the other factors. 
This is also visualized in Figure \ref{fig:ch5:sec1:iou_box_plot} and may seem like a small difference, but the statistical relevance is confirmed.
Interesting in the plot are the high amount of outliers and the wide range of the lower quarter of the box plot.
An explanation for this are demanding annotations from the domain $ anomaly $ or the failure of the methods on single annotations.
The number of outliers may seem large, but must be put in proportion to the total amount of data with \getNumberBenchmarkAnnotations annotations.

\begin{figure}
	\centering
	\includegraphics[width=0.6\textwidth]{figures/chap51_iou_boxplot.png}
	\caption[Box plots method on $ IoU $]{
		Box plot of the $ IoU $ for the four benchmark methods.
		It can be seen, that $ med \left( IoU_{DEXTR} \right) $ is slightly greater than the other factors, while $ med \left( IoU_{IOG} \right) $ has the smallest value.
		The classical methods to not differ significantly in their median values $ med \left( IoU_{Polygon} \right) $ and $ med \left( IoU_{Polygon} \right) $.
	} \label{fig:ch5:sec1:iou_box_plot}
\end{figure}


% Quantitative Comparison
\subsubsection{Quantitative Comparison}

% Motivation
To further diversify the evaluation, the methods were ranked based on their results.
This analysis aims to be more descriptive and less abstract than the presented statistical analysis.
As shown in Figure \ref{fig:ch5:sec1:iou_box_plot}, based on the $ IoU $ there is no method clearly superior.
%However, it is interesting to see which method performs best on different images based on a ranking.
%  for the four benchmark methods the $ IoU $ on one image is ranked.
In this analysis from all benchmark runs, the annotations from one image were used and averaged.
The averages of the $ IoU $ from the four methods were ranked from best to worst.
This was done for every image of the benchmark.
It has to be noted, that the methods may have been applied to the images differently often and one image may contain multiple annotations.
However, the amount of \getNumberBenchmarkAnnotations annotations ensures a reliable coverage of the images and multiple annotations from one image can be combined in this context due to their similarity.
In Table \ref{tab:ch5:best_performance_iou}, it is shown how often (in percent) each method performed best.
The best performance is achieved by polygon with 39.1\%, followed by \gls{dextr}, which performs best on one third of the images.
Further behind are watershed and \gls{iog}.
Similar to Figure \ref{fig:ch5:sec1:iou_box_plot}, \gls{iog} performs worst and is the first choice for 8.1\% of the images.
These results differ slightly from the previous evaluation because here only the best value counts and is averaged over the annotations, however the informative value remains. 

\begin{table}[h!]
	\centering
	\begin{tabular}{l|c c c c}
		Method					& polygon 	& watershed & DEXTR 	& IOG  \\
		\hline
		Percentage of images 	& 39.1\%	& 16.1\% 	& 33.3\% 	& 8.1\% \\
	\end{tabular}
	\caption[Method's best performance on $ IoU $]{
		Percentage of images the methods achieve the best $ IoU $.
		For each image a ranking is established, that defines which method achieves the best $ IoU $, based on the mean of all annotations.
		The percentages in this table show at how many images the corresponding method performed best.
	} \label{tab:ch5:best_performance_iou}
\end{table}


\subsection{Analysis Of Time}\label{ord:ch5:sec1:subsec3}
% RE-1466
In the following $time_{annot}$ is evaluated, the evaluation procedure is analog to the previous evaluation of the $IoU$.

\subsubsection{Data Transformation}

The histogram of the raw sample for the $time_{annot}$ does not fit a normal distribution as shown in Figure \ref{fig:ch5:sec1:time_raw}.
Instead, the data points are heavily skewed to the left, because $time_{annot}$ is usually short, but can also be larger.
\cite{PS16-Statistics} suggests to transform the sample by the logarithmic function 
\begin{equation} \label{equ:trans_time}
	X_{trans} = \log \left( X_{raw} \right) 
\end{equation}
to adapt the shape of a normal distribution, $X_{trans}$ is shown in Figure \ref{fig:ch5:sec1:time_transformed}.
$X_{trans}$ is similar to a normal distribution, which is also supported by the corresponding normal probability plot illustrated in Figure \ref{fig:ch5:sec1:time_probplot}

\begin{figure} [h]
	\centering
	\begin{subfigure}[t]{0.3\textwidth}
		\centering
		\includegraphics[width=\textwidth]{figures/chap51_time_raw.png}
		\caption{
			$ time_{Annot} $ as raw and unprocessed sample $ X_{raw} $.
		}\label{fig:ch5:sec1:time_raw}
	\end{subfigure}
	\hfill
	\begin{subfigure}[t]{0.3\textwidth}
		\centering
		\includegraphics[width=\textwidth]{figures/chap51_time_trans.png}
		\caption{
			Transformed sample $X_{trans}$ with fitted normal distribution.
		} \label{fig:ch5:sec1:time_transformed}
	\end{subfigure}
	\hfill
	\begin{subfigure}[t]{0.3\textwidth}
		\centering
		\includegraphics[width=\textwidth]{figures/chap51_time_probplot.png}
		\caption{
			Normal Probability Plot of $X_{trans}$.
		}\label{fig:ch5:sec1:time_probplot}
	\end{subfigure}
	\caption[Sample Transformation $ time $]{
		Transformation of the sample to achieve a normal distribution.
		In a) $X_{raw}$ is shown, which is skewed to the left and not normally distributed.
		The sample is transformed by Equation \ref{equ:trans_time}.
		The result is $X_{trans}$ now shows normal characteristics, as illustrated by the curve of the fitted normal distribution in b).
		The corresponding normal probability plot of $X_{trans}$ is shown in c), which confirms the normal characteristics of $X_{trans}$.
	}\label{fig:ch5:sec1:time_transformation_iou}
\end{figure}
% TODO Paddo: Könnte man da nicht sogar nochmal log-transformieren?

% Hypothesis testing
\subsubsection{Hypothesis Testing}

The setting for this hypothesis testing is analog to the previous tests on $IoU$.
In further evaluation the $time_{annot}$ is referred to as $time$, in order to enable a simple distinction between the factors.

First, more general tests are applied on the factors $time_{classical}$ and $time_{dl}$.
The Student's t-test, Kruskal-Wallis test, and Mann-Whitney are performed and their details are presented in Table \ref{tab:ch5:tests_on_time}.
All three tests come to the conclusion to reject $H_{0}$ and accept $H_{A}$.
This proves that the annotation time of \gls{dl} based methods is significantly faster than the annotation time of classical methods, as also illustrated in Figure \ref{fig:ch5:sec1:time_box_plot}.
The information value of this conclusion is especially expressive, due to the application of three different tests with various null hypotheses.

\begin{table}[h!]
	\centering
	\resizebox{\textwidth}{!}{
	\begin{tabular}{l|c c c}
		\toprule 		
		& Student's t-test	& Kruskal-Wallis test 	& Mann-Whitney U-test \\
		\midrule
		data			& $X_{trans}$		& $X_{raw}$ 	 		& $X_{raw}$ 	\\ 
		$H_{0}$			& $\overline{time}_{classical} = \overline{time}_{dl}$ & $med \left( time_{classical} \right)  = med \left( time_{dl} \right)$ & $ten \left( time_{dl} \right) = ten \left( time_{classical} \right)$ 		\\
		$H_{A}$		 	& $\overline{time}_{classical} > \overline{time}_{dl}$ & $med \left( time_{classical} \right) > med \left( time_{dl} \right) $ & $ten \left( time_{dl} \right) \not= ten \left( time_{classical}\right) $ 	\\
		$\alpha$		& $1\%$ 			& $1\%$ 		 		& $1\%$ 		\\ 	
		Statistic		& 28.6792			& 355045	     		& 627.875\\ 
		$\textnormal{\textit{p-value}}$ 
		& $4.8\cdot 10^{-155}$				& $7.2 \cdot 10^{-139}$ & $1.4 \cdot 10^{-138}$ 		\\ 
		$H_{0}$		  	& rejected 			& rejected		 		& rejected 		\\
		\bottomrule
	\end{tabular}}
	\caption[Hypothesis Tests on $ time $]{
		Overview and results of the various statistical test performed on the $ time $.
		The $ time $ is evaluated by various values as the mean, median and tendency of the sample.
		Each factor contains 629 annotations.
		If the $ \textnormal{\textit{p-value}} $ is lower than the significance level $ \alpha $, $ H_{0} $ is rejected and $ H_{A} $ is accepted.
		The same result is achieved by all three different statistical tests, which supports its reliability.
	}\label{tab:ch5:tests_on_time}
\end{table}
% Kruskal-Wallis Test for four factors rejects H0.
Second, the $ time $ is evaluated for the four benchmark methods by the Kruskal-Wallis test.
The null hypothesis 
\begin{equation}
	H_{0}: med \left( time_{Polygon} \right) = med \left( time_{Watershed} \right) = med \left( time_{IOG} \right) = med \left( time_{DEXTR} \right)
\end{equation}
assumes, that the median values do not differ significantly at $ \alpha=1\% $.
$ H_{A} $ states that $ H_{0} $ is not true.
The statistic returns $ \textnormal{\textit{p-value}} = 7.1 \cdot 10^{-141} $, as a result $ H_{0} $ is rejected and $ H_{A} $ accepted.
 
Based on the post analysis by the DSCF test \cite{CF91-dscf}, the median of the annotation time is not significantly different for the polygon and watershed method.
In contrast, the methods \gls{dextr} and \gls{iog} also differ significantly in $ time $ based on the median.

The differences between the factors are illustrated in Figure \ref{fig:ch5:sec1:time_box_plot}.
The \gls{iog} and \gls{dextr} method clearly demonstrate a lower annotation time than the polygon and watershed method.
It is extraordinary to note that for all methods the last quarter of the box plot covers a larger area than the first quarter.
One possible reason is that the different participants spent different amounts of time on particularly complicated objects.
Notable is that this effect is extreme for the polygon and watershed method, where approximately one quarter spent more than 60 seconds respectively 50 seconds on one annotation. 
This is perhaps caused by the possibility of editing as long as the user wants. 
In case of polygon and watershed the annotations do not converge as quickly as for the \gls{dl} based methods, i.e., changing the annotation significantly is still possible after a lot of clicks have already been made.
Therefore, more time was spent on editing with these methods, as mentioned at the beginning of this Section.

\begin{figure}
	\centering
	\includegraphics[width=0.9\textwidth]{figures/chap51_time_boxplot.png}
	\caption[Box plots of the methods on $ IoU  $]{
		Box plots of the $ time $ for the four benchmark methods.
		It can be clearly seen, that the required time to perform the \gls{dextr} and \gls{iog} method is lower than for the polygon and watershed method.
		This also applied for the $ med \left( time \right) $ of the single methods, which is statistically confirmed by the Kruskal-Wallis test.
		In general, the polygon and watershed method require a longer annotation time, where the last quarter of the box plot covers a relatively wide range with many outliers. 
		%Despite the difference
	} \label{fig:ch5:sec1:time_box_plot}
\end{figure}


Combining the results of the evaluation from $ IoU $ and the $ time $, it can be said that all methods may achieve an approximately equal level of accuracy.
But the difference between the two types of methods is that, \gls{dl} based method require significantly less time to achieve this level of \gls{iou}.



% Quantitative Comparison
\subsubsection{Quantitative Comparison}

% Motivation
As for the $ IoU $, also here, it is evaluated with respect to the $ time $, how often a method performed best. 
That means, for which percentage of images each method was the fastest.
The setup is the same as in the corresponding analysis of $ IoU $ and the results are presented in Table \ref{tab:ch5:best_performance_time}.

On average \gls{dextr} is the fastest method for 65.5\% of the images, followed by \gls{iog} with 29.9\%.
While polygon performs excellent in terms of $ IoU $, it it only in 1.2\% the best method based on the execution time.
Last, the watershed method never performs the fastest.
These results are confirmed by Figure \ref{fig:ch5:sec1:time_box_plot}, where it can be seen that the \gls{dl} based method need less annotation time than the classical methods.

\begin{table}[h!]
	\centering
	\begin{tabular}{l|c c c c}
		Method					& polygon 	& watershed & DEXTR 	& IOG  		\\
		\hline
		Percentage of images 	& 1.2\%		& 0\% 		& 65.5\% 	& 29.9\% 	\\
	\end{tabular}
	\caption[Method's best performance on $ time $]{
		Percentage of images the methods are the fasted in terms of $ time $.
		For each image a ranking is established, that defines which method requires the lowest $ time $, based on the mean time of all annotations.
		The percentages in this table show at how many images the corresponding method was the fastest.
	} \label{tab:ch5:best_performance_time}
\end{table}

